{
 "cells": [
  {
   "cell_type": "heading",
   "metadata": {
    "collapsed": true
   },
   "level": 1,
   "source": [
    "Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abalata\\AppData\\Local\\Continuum\\anaconda3\\python.exe\n['', 'C:\\\\Users\\\\abalata\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\envs', 'C:\\\\Users\\\\abalata\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\python37.zip', 'C:\\\\Users\\\\abalata\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\DLLs', 'C:\\\\Users\\\\abalata\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib', 'C:\\\\Users\\\\abalata\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3', 'C:\\\\Users\\\\abalata\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\site-packages', 'C:\\\\Users\\\\abalata\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\abalata\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\abalata\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\abalata\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\abalata\\\\.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tweepy'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c4921259bfa8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mauth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOAuthHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"YzWFDST42FGUpQrqnFd6cT85u\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Ois5i7dau00xpluXjFPuU3Uu20UjDxd9KXbQjd7duXEO370iu8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_access_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"1089235299862040576-gxsMbZg9nQgbooxCpsJ33ETDKb6IM5\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"bSg2xKANcbIYhxEpL8OMwZIY7gXXbkc2wUkStxMSbU4K7\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mapi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAPI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tweepy'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import tweepy\n",
    "auth = tweepy.OAuthHandler(\"YzWFDST42FGUpQrqnFd6cT85u\", \"Ois5i7dau00xpluXjFPuU3Uu20UjDxd9KXbQjd7duXEO370iu8\")\n",
    "auth.set_access_token(\"1089235299862040576-gxsMbZg9nQgbooxCpsJ33ETDKb6IM5\", \"bSg2xKANcbIYhxEpL8OMwZIY7gXXbkc2wUkStxMSbU4K7\")\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get place Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = api.geo_search(query=\"USA\", granularity=\"country\")\n",
    "place_id = places[0].id\n",
    "print(place_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "def cleanAndNormalizeText(data):\n",
    "    # tokenize\n",
    "    tokenize = word_tokenize(data)\n",
    "    # remove stop words\n",
    "    filterText = [w for w in tokenize if w not in stop_words]\n",
    "    filterText = [w for w in filterText if not len(w) <= 1]\n",
    "\n",
    "    # stem\n",
    "    ps = PorterStemmer()\n",
    "    for i in range(len(filterText)-1):\n",
    "        if len(filterText[i]) > 1:\n",
    "            try:\n",
    "                filterText[i] = ps.stem(filterText[i])\n",
    "            except Exception as e:\n",
    "                filterText[i] = filterText[i]\n",
    "\n",
    "    return ' '.join(filterText)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAN CHANGE THE QUERY WITH HASHTAG\n",
    "# MAYBE NEED STREAMING PU IN ANOTHER WAY?\n",
    "\n",
    "tweetsData = []\n",
    "for tweet in tweepy.Cursor(api.search, q=\"place:%s\" % place_id).items(15000):\n",
    "    text = cleanAndNormalizeText(tweet.text)\n",
    "    tweetsData.append([tweet.id, text])\n",
    "trainTable = pd.DataFrame(tweetsData, columns=['ID', 'text'])\n",
    "print(trainTable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
